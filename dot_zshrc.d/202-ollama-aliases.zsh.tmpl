# LLM Local (Ollama)
alias chat='ollama run llama3'
alias coder='ollama run deepseek-coder'


alias -- thinker='ollama pull deepseek-r1:8b'
alias -- chat='ollama pull llama3.1:8b'
alias -- coder='ollama pull deepseek-coder:6.7b-instruct-q4_K_M'
