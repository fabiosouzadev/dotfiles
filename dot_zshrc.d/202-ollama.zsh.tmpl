# LLM Local (Ollama)
export OLLAMA_API_BASE=http://127.0.0.1:11434
export OLLAMA_CONTEXT_LENGTH=131072


#Alias
alias -- thinker='ollama run deepseek-r1:8b'
alias -- chat='ollama run llama3.1:8b'
alias -- coder='ollama run deepseek-coder:6.7b-instruct-q4_K_M'
